{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9c07d2-13ce-4658-baee-8eaed42570bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9a6e49-c687-49ee-a8c8-0327e6e81609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_info(soup):\n",
    "    informacion = {}\n",
    "    try:\n",
    "        informacion['precio'] = soup.find(\"span\", attrs = {\"class\": \"_tyxjp1\"}).text.replace('\\xa0','')\n",
    "        informacion['titulo_anuncio'] = browser.find_element(By.CLASS_NAME, '_1n81at5').text\n",
    "        informacion['tipo_alojamineto'] = browser.find_element(By.CLASS_NAME, '_cv5qq4').text.split(':')[1].split('.')[0].strip()\n",
    "        informacion['numero_personas'] = browser.find_element(By.CLASS_NAME, '_tqmy57').text.split(\"\\n\")[1].split(\"·\")[0].strip()\n",
    "        informacion['n_dormitorios'] = browser.find_element(By.CLASS_NAME, '_tqmy57').text.split(\"\\n\")[1].split(\"·\")[1].strip()\n",
    "        informacion['nunmero_camas'] = browser.find_element(By.CLASS_NAME, '_tqmy57').text.split(\"\\n\")[1].split(\"·\")[2].strip()\n",
    "        informacion['nunmero_banos'] = browser.find_element(By.CLASS_NAME, '_tqmy57').text.split(\"\\n\")[1].split(\"·\")[3].strip()\n",
    "        informacion['valoracion'] = browser.find_element(By.CLASS_NAME, '_klarpw').text.split(' ')[0]\n",
    "        informacion['n_evaluaciones'] = browser.find_element(By.CLASS_NAME, '_klarpw').text.split(' ')[1].replace('·\\n','')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    return informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c542b233-c6ea-423c-8c42-aac911eacd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avanzar_hasta_el_final(soup):\n",
    "    sleep(1)\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        sleep(1)\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6284c6e-ec7a-4044-be0b-ef4ea079a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://www.airbnb.es/s/\"\n",
    "comunidades = ['valencia', 'galicia', 'asturias', 'cantabria', 'pais_vasco', 'navarra', 'la_rioja', 'aragon', 'cataluña', 'castilla_y_leon', 'madrid', 'comunidad_valenciana', 'castilla_la_mancha', 'murcia', 'extremadura', 'andalucia', 'ceuta', 'melilla', 'baleares' 'islas_canarias']\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "browser.maximize_window()\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "results = []\n",
    "    \n",
    "for comunidad in comunidades:\n",
    "    url = url_base + comunidad + \"/homes\"\n",
    "    browser.get(url)\n",
    "\n",
    "    try:\n",
    "        accept_button = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[5]/div/div/div[1]/div/div[4]/section/div[2]/div[2]')))\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "            WebDriverWait(browser, 5).until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'c1l1h97y')))\n",
    "            ad_elements = browser.find_elements(By.CLASS_NAME, 'c1l1h97y')\n",
    "\n",
    "            for el in ad_elements:\n",
    "            \n",
    "                url = el.find_element(By.XPATH, './/a').get_attribute('href')\n",
    "            \n",
    "                results.append((comunidad, url))\n",
    "            \n",
    "            avanzar_hasta_el_final(soup)\n",
    "            try:\n",
    "                siguiente = browser.find_element(By.XPATH, '//a[@aria-label=\"Siguiente\"]') \n",
    "                siguiente.click()\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb7deebf-ace3-4092-afc5-9cc6591f33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80db057c-33e6-4646-915d-ee188c715a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns = ['comunidad', 'url']).to_csv(\"lugares.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fb5cdb-87c3-4dca-a8dc-7b2b38327ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls = pd.read_csv(\"lugares.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71549f65-16b2-4f39-9108-9f98cafa3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "INICIO = 0\n",
    "FIN = 6000\n",
    "df_urls = df_urls[INICIO:FIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb249b06-3b6e-41b5-ba3e-c856a9badf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezar desde cero\n",
    "\n",
    "numero_aleatorio = random.randint(1, 1000000000)\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "infos = []\n",
    "for idx, row in df_urls.iterrows():\n",
    "    url = row['url']\n",
    "    browser.get(url)\n",
    "    browser.maximize_window()\n",
    "    sleep(2)\n",
    "        \n",
    "    try:\n",
    "        cerrar_traduccion = browser.find_element(By.CLASS_NAME, '_1piuevz').click()\n",
    "        accept_button = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[5]/div/div/div[1]/div/div[4]/section/div[2]/div[2]')))\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    response = requests.get\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    sleep(1)\n",
    "    info = obtener_info(soup)\n",
    "    info[\"comunidad\"] = row['comunidad']\n",
    "    info[\"url\"] = url\n",
    "    sleep(4)\n",
    "    infos.append(info)\n",
    "        \n",
    "    info_df = pd.DataFrame(infos)\n",
    "    info_df.to_csv(f\"info_{numero_aleatorio}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b350f441-8347-4dde-b6f7-d5b9faaf473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar desde copia de seguridad\n",
    "\n",
    "numero_aleatorio = random.randint(1, 1000000000)\n",
    "\n",
    "info_df = pd.read_csv(\"info_397144036.csv\")\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "for idx, row in df_urls.iterrows():\n",
    "    url = row['url']\n",
    "    if url in info_df.url.values:\n",
    "        continue\n",
    "    \n",
    "    browser.get(url)\n",
    "    browser.maximize_window()\n",
    "    sleep(2)\n",
    "        \n",
    "    try:\n",
    "        cerrar_traduccion = browser.find_element(By.CLASS_NAME, '_1piuevz').click()\n",
    "        accept_button = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[5]/div/div/div[1]/div/div[4]/section/div[2]/div[2]')))\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    response = requests.get\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    sleep(1)\n",
    "    info = obtener_info(soup)\n",
    "    info[\"comunidad\"] = row['comunidad']\n",
    "    info[\"url\"] = url\n",
    "    sleep(4)\n",
    "    info_df.loc[len(info_df), :] = info\n",
    "    info_df.to_csv(f\"info_{numero_aleatorio}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2297ad-d430-4bc1-bf44-94c1536865b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf5c7e-8046-44a2-b671-75c4e2fcc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://www.bankinter.com/blog/finanzas-personales/precio-vivienda-ciudades\"\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = bs(r.text,'html.parser')\n",
    "\n",
    "tabla = soup.find('tbody')\n",
    "\n",
    "datos = []\n",
    "\n",
    "if tabla:\n",
    "    filas = tabla.find_all('tr')\n",
    "    \n",
    "    for fila in filas:\n",
    "        celdas = fila.find_all('td')\n",
    "        if len(celdas) == 4:\n",
    "            ciudad = celdas[0].text.strip()\n",
    "            precio_m2 = celdas[1].text.strip()\n",
    "            variacion_anual = celdas[2].text.strip()\n",
    "            datos.append((ciudad, precio_m2, variacion_anual))\n",
    "    \n",
    "    df = pd.DataFrame(datos, columns=['Ciudad', 'Precio por m2', 'Variación Anual'])\n",
    "    \n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e0fe9-52bd-45c9-b684-bc895dc6c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"preciom2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
